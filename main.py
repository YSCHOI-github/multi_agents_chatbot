import streamlit as st
import os
import tempfile
import concurrent.futures
import json
from utils import PDFLoader, VectorStore, AIAgent, HeadAgent, ConversationManager

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PDF ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'vector_stores' not in st.session_state:
    st.session_state.vector_stores = {}
if 'pdf_names' not in st.session_state:
    st.session_state.pdf_names = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'conversation_manager' not in st.session_state:
    st.session_state.conversation_manager = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""
if 'temp_dir' not in st.session_state:
    st.session_state.temp_dir = tempfile.mkdtemp()

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ“š PDF ë¬¸ì„œ ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ì±—ë´‡")
st.markdown("""
ì´ ì±—ë´‡ì€ ì—¬ëŸ¬ PDF ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
ê° ë¬¸ì„œë³„ AI ì—ì´ì „íŠ¸ê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³ , í—¤ë“œ ì—ì´ì „íŠ¸ê°€ ì´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
""")

# ì‚¬ì´ë“œë°” - API í‚¤ ì…ë ¥
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    api_key = st.text_input("Google API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", value=st.session_state.api_key)
    if api_key:
        st.session_state.api_key = api_key

    st.header("ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥)", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        process_button = st.button("PDF ì²˜ë¦¬ ì‹œì‘")
        if process_button:
            with st.spinner("PDF íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.vector_stores = {}
                st.session_state.pdf_names = []

                for uploaded_file in uploaded_files:
                    # ìˆ˜ì •ëœ ë¶€ë¶„: BytesIO ê°ì²´ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì„ì‹œ íŒŒì¼ ìƒì„± ë°©ì§€
                    try:
                        pdf_loader = PDFLoader(uploaded_file)
                        pdf_text = pdf_loader.extract_text()
                        
                        if not pdf_text.startswith("Error"):
                            chunks = pdf_loader.chunk_text(pdf_text)
                            vstore = VectorStore()
                            vstore.add_chunks(chunks, uploaded_file.name)
                            
                            if vstore.build_index():
                                st.session_state.vector_stores[uploaded_file.name] = vstore
                                st.session_state.pdf_names.append(uploaded_file.name)
                                st.success(f"{uploaded_file.name} ì²˜ë¦¬ ì™„ë£Œ!")
                            else:
                                st.error(f"{uploaded_file.name} ì¸ë±ì‹± ì‹¤íŒ¨")
                        else:
                            st.error(pdf_text)
                    except Exception as e:
                        st.error(f"{uploaded_file.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

                if st.session_state.vector_stores:
                    # ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”
                    st.session_state.conversation_manager = ConversationManager()
                    st.success(f"ëª¨ë“  PDF íŒŒì¼ ì²˜ë¦¬ ë° ì¸ë±ì‹± ì™„ë£Œ! ì´ {len(st.session_state.vector_stores)}ê°œì˜ ë¬¸ì„œê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("ì¸ë±ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    if st.session_state.pdf_names:
        st.header("ğŸ“‹ ì²˜ë¦¬ëœ PDF íŒŒì¼")
        st.write(f"ì´ {len(st.session_state.pdf_names)}ê°œì˜ ë¬¸ì„œê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        for pdf_name in st.session_state.pdf_names:
            st.write(f"- {pdf_name}")

# ë‹¨ì¼ ë¬¸ì„œì— ëŒ€í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
def process_document(doc_name, vector_store, user_query, api_key, conversation_history=None):
    contexts = vector_store.search(user_query, top_k=3)
    if contexts:
        agent = AIAgent(api_key, doc_name)
        return agent.generate_response(user_query, contexts, conversation_history)
    return None

# ë©”ì¸ í™”ë©´ - ì±— ì¸í„°í˜ì´ìŠ¤
if st.session_state.pdf_names and st.session_state.api_key:
    st.header("ğŸ’¬ ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸°")
    for chat in st.session_state.chat_history:
        if chat["role"] == "user":
            st.markdown(f'<div style="background-color: #f0f2f6; padding: 10px; border-radius: 10px; margin-bottom: 10px;"><strong>ì§ˆë¬¸:</strong> {chat["content"]}</div>', unsafe_allow_html=True)
        else:
            st.markdown(f'<div style="background-color: #e6f7ff; padding: 10px; border-radius: 10px; margin-bottom: 10px;"><strong>ë‹µë³€:</strong> {chat["content"]}</div>', unsafe_allow_html=True)

    user_query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_query")

    if st.button("ì§ˆë¬¸í•˜ê¸°") and user_query:
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
            st.session_state.chat_history.append({"role": "user", "content": user_query})
            
            # ëŒ€í™” ê´€ë¦¬ìì— í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
            if st.session_state.conversation_manager:
                st.session_state.conversation_manager.add_user_message(user_query)
            
            # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
            conversation_history = []
            if st.session_state.conversation_manager:
                conversation_history = st.session_state.conversation_manager.get_conversation_history()

            # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‘ì—… ì¤€ë¹„
            doc_tasks = []
            for doc_name in st.session_state.pdf_names:
                vector_store = st.session_state.vector_stores.get(doc_name)
                if vector_store:
                    doc_tasks.append((doc_name, vector_store, user_query, st.session_state.api_key, conversation_history))
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
            agent_responses = []
            progress_placeholder = st.empty()
            progress_placeholder.info(f"0/{len(doc_tasks)} ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ...")
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                # ê° ë¬¸ì„œë³„ ì²˜ë¦¬ ì‘ì—… ì œì¶œ
                future_to_doc = {
                    executor.submit(process_document, doc_name, vector_store, user_query, api_key, conversation_history): doc_name 
                    for doc_name, vector_store, user_query, api_key, conversation_history in doc_tasks
                }
                
                # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
                completed = 0
                for future in concurrent.futures.as_completed(future_to_doc):
                    doc_name = future_to_doc[future]
                    try:
                        response = future.result()
                        if response:
                            agent_responses.append(response)
                    except Exception as e:
                        st.error(f"{doc_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    
                    completed += 1
                    progress_placeholder.info(f"{completed}/{len(doc_tasks)} ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ...")
            
            progress_placeholder.empty()

            with st.expander(f"ê° ë¬¸ì„œë³„ ë‹µë³€ ìƒì„¸ ì •ë³´ (ì´ {len(agent_responses)}ê°œ ë¬¸ì„œ)"):
                for resp in agent_responses:
                    st.subheader(f"{resp['source']}ì˜ ë‹µë³€")
                    st.write(resp['response'])
                    st.markdown("**ì°¸ê³ í•œ ì»¨í…ìŠ¤íŠ¸:**")
                    for ctx in resp['context']:
                        st.markdown(f"- ìœ ì‚¬ë„ ì ìˆ˜: {ctx['score']:.4f}")
                        st.markdown(f"```\n{ctx['chunk'][:200]}...\n```")

            st.info("í—¤ë“œ ì—ì´ì „íŠ¸ê°€ ìµœì¢… ë‹µë³€ì„ ì¢…í•©í•˜ëŠ” ì¤‘...")
            head_agent = HeadAgent(st.session_state.api_key)
            final_response = head_agent.synthesize_responses(user_query, agent_responses, conversation_history)

            # ëŒ€í™” ê¸°ë¡ì— ë‹µë³€ ì¶”ê°€
            st.session_state.chat_history.append({"role": "assistant", "content": final_response})
            
            # ëŒ€í™” ê´€ë¦¬ìì— ë‹µë³€ ì¶”ê°€
            if st.session_state.conversation_manager:
                st.session_state.conversation_manager.add_assistant_message(final_response)
            
            st.rerun()

elif not st.session_state.api_key:
    st.warning("ì‚¬ìš©ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì— Google API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
elif not st.session_state.pdf_names:
    st.warning("ì‚¬ìš©ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”.")